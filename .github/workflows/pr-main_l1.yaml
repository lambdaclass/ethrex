name: L1
on:
  push:
    branches: ["main"]
  merge_group:
  pull_request:
    branches: ["**"]
    paths-ignore:
      - "crates/l2/**" # Behind a feature flag not used in this workflow

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  lint:
    # "Lint" is a required check, don't change the name
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - name: Checkout sources
        uses: actions/checkout@v4
      - name: Setup Rust Environment
        uses: ./.github/actions/setup-rust
        with:
          components: rustfmt, clippy

      - name: Run cargo check
        run: cargo check --workspace

      - name: Run cargo clippy
        run: |
          cargo clippy --workspace -- -D warnings
          cargo clippy -- -D warnings

      - name: Run cargo fmt
        run: |
          cargo fmt --all -- --check

  test:
    # "Test" is a required check, don't change the name
    name: Test
    runs-on: ubuntu-latest
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - name: Checkout sources
        uses: actions/checkout@v4
      - name: Setup Rust Environment
        uses: ./.github/actions/setup-rust

      - name: Run unit tests
        run: |
          make test

      - name: Run Blockchain EF tests
        run: |
          make -C tooling/ef_tests/blockchain test

  docker_build:
    name: Build Docker
    runs-on: ubuntu-latest
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - uses: actions/checkout@v4
      - id: docker
        name: Build Ethrex Docker Image
        uses: ./.github/actions/build-docker
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ethrex_image
          path: /tmp/ethrex_image.tar

  run-assertoor:
    name: Assertoor - ${{ matrix.name }}
    runs-on: ubuntu-latest
    needs: [docker_build]
    if: ${{ github.event_name != 'merge_group' }}
    strategy:
      fail-fast: true
      matrix:
        include:
          - name: Transaction Check
            enclave_name: "ethrex-assertoor-tx"
            ethereum_package_args: "./.github/config/assertoor/network_params_tx.yaml"
          - name: Blob & Stability Check
            enclave_name: "ethrex-assertoor-blob"
            ethereum_package_args: "./.github/config/assertoor/network_params_blob.yaml"
          # Flaky, reenable when fixed
          # - name: Ethrex Only With Different Consensus Clients Check
          #   enclave_name: "ethrex-different-consensus-assertoor"
          #   ethereum_package_args: "./.github/config/assertoor/network_params_ethrex_multiple_cl.yaml"

    steps:
      - uses: actions/checkout@v4

      - name: Download etherex image artifact
        uses: actions/download-artifact@v4
        with:
          name: ethrex_image
          path: /tmp

      - name: Load image
        run: |
          docker load --input /tmp/ethrex_image.tar

      - name: Run assertoor
        uses: ethpandaops/kurtosis-assertoor-github-action@v1
        with:
          enclave_name: ${{ matrix.enclave_name }}
          kurtosis_version: "1.10.2"
          ethereum_package_url: "github.com/ethpandaops/ethereum-package"
          ethereum_package_branch: "82e5a7178138d892c0c31c3839c89d53ffd42d9a"
          ethereum_package_args: ${{ matrix.ethereum_package_args }}

  run-hive:
    name: Hive - ${{ matrix.name }}
    runs-on: ubuntu-latest
    needs: [docker_build]
    if: ${{ github.event_name != 'merge_group' }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: "Rpc Compat tests"
            simulation: ethereum/rpc-compat
            limit: ""
            hive_repository: lambdaclass/hive
            hive_version: 115f4d6ef1bdd2bfcabe29ec60424f6327e92f43
            artifact_prefix: rpc_compat
          - name: "Devp2p tests"
            simulation: devp2p
            limit: discv4|eth|snap/Ping|Findnode/WithoutEndpointProof|Findnode/PastExpiration|Amplification|Status|StorageRanges|ByteCodes|GetBlockHeaders|SimultaneousRequests|SameRequestID|ZeroRequestID|GetBlockBodies|MaliciousHandshake|MaliciousStatus|Transaction|NewPooledTxs|GetBlockReceipts|LargeTxRequest|InvalidTxs|BlockRangeUpdate
            # AccountRange and GetTrieNodes don't pass anymore.
            # Findnode/BasicFindnode fails due to packets being processed out of order
            # Findnode/UnsolicitedNeighbors flaky in CI very occasionally. When fixed replace all "Findnode/<test>" with "Findnode"
            hive_repository: lambdaclass/hive
            hive_version: 115f4d6ef1bdd2bfcabe29ec60424f6327e92f43
            artifact_prefix: devp2p
          - name: "Engine Auth and EC tests"
            simulation: ethereum/engine
            limit: engine-(auth|exchange-capabilities)/
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: engine_auth_ec
          - name: "Cancun Engine tests"
            simulation: ethereum/engine
            limit: "engine-cancun"
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: engine_cancun
          - name: "Paris Engine tests"
            simulation: ethereum/engine
            limit: "engine-api"
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: engine_paris
          - name: "Engine withdrawal tests"
            simulation: ethereum/engine
            limit: "engine-withdrawals/Corrupted Block Hash Payload|Empty Withdrawals|engine-withdrawals test loader|GetPayloadBodies|GetPayloadV2 Block Value|Max Initcode Size|Sync after 2 blocks - Withdrawals on Genesis|Withdraw many accounts|Withdraw to a single account|Withdraw to two accounts|Withdraw zero amount|Withdraw many accounts|Withdrawals Fork on Block 1 - 1 Block Re-Org|Withdrawals Fork on Block 1 - 8 Block Re-Org NewPayload|Withdrawals Fork on Block 2|Withdrawals Fork on Block 3|Withdrawals Fork on Block 8 - 10 Block Re-Org NewPayload|Withdrawals Fork on Canonical Block 8 / Side Block 7 - 10 Block Re-Org [^S]|Withdrawals Fork on Canonical Block 8 / Side Block 9 - 10 Block Re-Org [^S]"
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: engine_withdrawals
          - name: "Sync full"
            simulation: ethereum/sync
            limit: ""
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: sync_full
          - name: "Sync snap"
            simulation: ethereum/sync
            limit: ""
            hive_repository: ethereum/hive
            hive_version: 2b7a9c007770b10cb1a242a6c6de88c87a383e5a
            artifact_prefix: sync_snap
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - name: Checkout sources
        uses: actions/checkout@v4

      - name: Download ethrex image artifact
        uses: actions/download-artifact@v4
        with:
          name: ethrex_image
          path: /tmp

      - name: Load image
        run: |
          docker load --input /tmp/ethrex_image.tar

      - name: Load hive client config
        id: client-config
        shell: bash
        run: |
          {
            echo "config<<EOF"
            cat .github/config/hive/clients.yaml
            echo "EOF"
          } >>"$GITHUB_OUTPUT"

      - name: Determine hive flags
        id: hive-flags
        shell: bash
        env:
          SIM_LIMIT: ${{ matrix.limit }}
        run: |
          FLAGS='--sim.parallelism 16 --sim.loglevel 1'
          if [[ -n "$SIM_LIMIT" ]]; then
            escaped_limit=${SIM_LIMIT//\'/\'\\\'\'}
            FLAGS+=" --sim.limit '$escaped_limit'"
          fi
          echo "flags=$FLAGS" >> "$GITHUB_OUTPUT"

      - name: Run Hive Simulation
        id: run-hive-action
        uses: ethpandaops/hive-github-action@v0.5.0
        with:
          hive_repository: ${{ matrix.hive_repository }}
          hive_version: ${{ matrix.hive_version }}
          simulator: ${{ matrix.simulation }}
          client: ethrex
          client_config: ${{ steps.client-config.outputs.config }}
          extra_flags: ${{ steps.hive-flags.outputs.flags }}
          workflow_artifact_upload: true
          workflow_artifact_prefix: ${{ matrix.artifact_prefix }}

      - name: Check Hive Results For Failures
        id: verify-hive-results
        if: ${{ success() }}
        shell: bash
        run: |
          set -euo pipefail
          results_dir="src/results"

          if [ ! -d "$results_dir" ]; then
            echo "Hive results directory '$results_dir' not found"
            exit 1
          fi

          shopt -s nullglob
          json_files=("$results_dir"/*.json)
          shopt -u nullglob

          if [ ${#json_files[@]} -eq 0 ]; then
            echo "No Hive JSON result files found in $results_dir"
            exit 1
          fi

          failures=0
          failed_logs_root="$results_dir/failed_logs"
          mkdir -p "$failed_logs_root"

          for json_file in "${json_files[@]}"; do
            if [[ "$json_file" == *"hive.json" ]]; then
              continue
            fi

            suite_name=$(jq -r '.name // empty' "$json_file")
            failed_cases=$(jq '[.testCases[]? | select(.summaryResult.pass != true)] | length' "$json_file")

            if [ "$failed_cases" -gt 0 ]; then
              echo "Detected $failed_cases failing test case(s) in ${suite_name:-$(basename "$json_file")}"
              failure_list=$(jq -r '
                .testCases[]?
                | select(.summaryResult.pass != true)
                | . as $case
                | ($case.summaryResult // {}) as $summary
                | ($summary.message // $summary.reason // $summary.error // "") as $message
                | (if $summary.log?
                   then "log lines "
                     + (($summary.log.begin // "?") | tostring)
                     + "-"
                     + (($summary.log.end // "?") | tostring)
                   else ""
                   end) as $log_hint
                | (if $message != "" then $message else $log_hint end) as $detail
                | (if $case.clientInfo?
                   then ($case.clientInfo
                         | to_entries
                         | map((.value.name // .key) + ": " + (.value.logFile // "unknown log"))
                         | join("; "))
                   else ""
                   end) as $clients
                | "- " + ($case.name // "unknown test")
                  + (if $detail != "" then ": " + $detail else "" end)
                  + (if $clients != "" then " (client logs: " + $clients + ")" else "" end)
              ' "$json_file")

              printf '%s\n' "$failure_list"

              suite_slug_raw=${suite_name:-$(basename "$json_file" .json)}
              suite_slug=$(printf '%s' "$suite_slug_raw" | tr '[:upper:]' '[:lower:]')
              suite_slug=$(printf '%s' "$suite_slug" | sed -E 's/[^a-z0-9._-]+/-/g')
              suite_slug=${suite_slug#-}
              suite_slug=${suite_slug%-}
              suite_dir="$failed_logs_root/${suite_slug:-suite}"
              mkdir -p "$suite_dir"

              printf '%s\n' "Detected $failed_cases failing test case(s) in ${suite_name:-$(basename "$json_file")}" >> "$suite_dir/failed-tests.txt"
              printf '%s\n' "$failure_list" >> "$suite_dir/failed-tests.txt"
              printf '\n' >> "$suite_dir/failed-tests.txt"

              cp "$json_file" "$suite_dir/"

              mapfile -t suite_logs < <(
                jq -r '
                  [
                    .simLog?,
                    .testDetailsLog?,
                    (.testCases[]? | select(.summaryResult.pass != true) | .clientInfo? | to_entries? // [] | map(.value.logFile? // empty) | .[]),
                    (.testCases[]? | select(.summaryResult.pass != true) | .summaryResult.logFile?),
                    (.testCases[]? | select(.summaryResult.pass != true) | .logFile?)
                  ]
                  | map(select(. != null and . != ""))
                  | unique[]
                ' "$json_file" 2>/dev/null
              ) || true

              for log_rel in "${suite_logs[@]}"; do
                [ -z "$log_rel" ] && continue
                log_path="$results_dir/$log_rel"
                if [ -f "$log_path" ]; then
                  target_path="$suite_dir/$log_rel"
                  mkdir -p "$(dirname "$target_path")"
                  if [ ! -f "$target_path" ]; then
                    cp "$log_path" "$target_path"
                  fi
                else
                  echo "Referenced log '$log_rel' not found for suite ${suite_name:-$(basename "$json_file")}"
                fi
              done

              echo "Saved Hive failure artifacts to $suite_dir"

              failures=$((failures + failed_cases))
            fi
          done

          if [ "$failures" -gt 0 ]; then
            echo "Hive reported $failures failing test cases in total"
            exit 1
          fi

          echo "Hive reported no failing test cases."

      - name: Upload Hive Failure Logs
        if: ${{ failure() && steps.verify-hive-results.conclusion == 'failure' }}
        uses: actions/upload-artifact@v4
        with:
          name: hive_failed_logs_${{ matrix.artifact_prefix }}
          path: src/results/failed_logs
          if-no-files-found: warn

  # The purpose of this job is to add it as a required check in GitHub so that we don't have to add every individual job as a required check
  all-tests:
    # "Integration Test" is a required check, don't change the name
    name: Integration Test
    runs-on: ubuntu-latest
    needs: [run-assertoor, run-hive]
    # Make sure this job runs even if the previous jobs failed or were skipped
    if: ${{ always() && needs.run-assertoor.result != 'skipped' && needs.run-hive.result != 'skipped' }}
    steps:
      - name: Check if any job failed
        run: |
          if [ "${{ needs.run-assertoor.result }}" != "success" ]; then
            echo "Job Assertoor Tx Check failed"
            exit 1
          fi

          if [ "${{ needs.run-hive.result }}" != "success" ]; then
            echo "Job Hive failed"
            exit 1
          fi

  reorg-tests:
    name: Reorg Tests
    runs-on: ubuntu-latest
    if: ${{ github.event_name != 'merge_group' }}
    steps:
      - name: Free Disk Space (Ubuntu)
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          tool-cache: false
          large-packages: false

      - name: Checkout sources
        uses: actions/checkout@v4

      - name: Setup Rust Environment
        uses: ./.github/actions/setup-rust

      - name: Compile ethrex binary
        run: cargo build --bin ethrex

      - name: Run reorg tests
        run: cd tooling/reorgs && cargo run
