# Experiment: [Name]

**Date:** YYYY-MM-DD
**Author:** [Name]
**Idea:** [Link to ideas.md row]
**Branch:** [Branch name]
**Status:** In Progress / Completed / Abandoned

## Hypothesis

What improvement do we expect and why?

## Changes Made

Brief description of the implementation:
- File 1: What changed
- File 2: What changed

## Methodology

### Benchmark Configuration
- Benchmark: Mainnet replay / perf_bench / other
- Blocks: [range or count]
- Hardware: [CPU, RAM, storage type]
- Runs: [number of runs for statistical significance]

### Baseline
```
[Baseline benchmark output]
```

### After Changes
```
[New benchmark output]
```

## Results

| Metric | Baseline | After | Change |
|--------|----------|-------|--------|
| Mgas/s | | | |
| Block time (mean) | | | |
| Block time (p99) | | | |

## Analysis

What do the results tell us? Any unexpected findings?

## Regressions

Did any benchmarks get worse? Which ones and by how much?

## Decision

- [ ] Merge as-is
- [ ] Merge with modifications
- [ ] Needs more investigation
- [ ] Abandon

## Follow-up

Any related ideas or next steps identified during this experiment?
